{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ak-smaiProject_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32NCS835hg1h",
        "outputId": "cc76722d-82bb-4cd8-98f8-262d4e082b78"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIUa6z3yrfFy",
        "outputId": "f2b237de-ac6c-455c-df7e-44c3c64883b5"
      },
      "source": [
        "#Adjusting path\n",
        "#/train_data.xml\n",
        "%cd \"/content/drive/MyDrive/Colab Notebooks/akmam\"\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/akmam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ0hFdV_Atbp"
      },
      "source": [
        "### Data Extraction from XML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPeM8r-ur8td"
      },
      "source": [
        "# Loading the dataset now\n",
        "import xml.etree.ElementTree as ET\n",
        "tree = ET.parse('train_data.xml')\n",
        "reviews = tree.getroot()\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqjwnstziveb",
        "outputId": "b6f7d459-019f-4a96-c053-78e82117b154"
      },
      "source": [
        "reviewsentencearray=[]\n",
        "aspectarray=[]\n",
        "polarityarray=[]\n",
        "ridarray = []\n",
        "\n",
        "i=-1\n",
        "\n",
        "numsentences=0\n",
        "for review in reviews:\n",
        "  i+=1\n",
        "  if(i==299):\n",
        "    ridarray.append(i)\n",
        "    polarityarray.append(0.0)\n",
        "    aspectarray.append('FOOD#QUALITY')\n",
        "    reviewsentencearray.append(\"Food is very bad\")\n",
        "\n",
        "  \n",
        "  sentences = review.find(\"./sentences\")\n",
        "  \n",
        "  for sentence in sentences:\n",
        "    numsentences+=1\n",
        "    \n",
        "    text = sentence.find(\"./text\")\n",
        "\n",
        "    opinions = sentence.findall(\"./Opinions/Opinion\")\n",
        "    if(opinions == [] or opinions == None ):\n",
        "      continue\n",
        "    for opinion in opinions:\n",
        "    \n",
        "      ridarray.append(i)\n",
        "      ##polarityarray.append(opinion.attrib['polarity'])\n",
        "      if(opinion.attrib['polarity'] == \"negative\"):\n",
        "        polarityarray.append(0.0)\n",
        "      elif(opinion.attrib['polarity'] == \"neutral\"):\n",
        "        polarityarray.append(0.5)\n",
        "      elif(opinion.attrib['polarity'] == \"positive\"):\n",
        "        polarityarray.append(1.0)\n",
        "\n",
        "      aspectarray.append(opinion.attrib['category'])\n",
        "      reviewsentencearray.append(text.text)\n",
        "\n",
        "\n",
        "    \n",
        "  \n",
        "# print(numsentences)  \n",
        "# print(len(reviewsentencearray))\n",
        "# print(len(aspectarray))\n",
        "# print(len(polarityarray))\n",
        "### 2008, 2009 start of 305\n",
        "print(ridarray[2008])\n",
        "revIndex=[]\n",
        "prev =0\n",
        "i=0\n",
        "for rid  in ridarray:\n",
        "  if(prev == rid):\n",
        "    i+=1\n",
        "  else:\n",
        "    revIndex.append(i)\n",
        "    i=1\n",
        "    prev=rid\n",
        "\n",
        "maxi = -1\n",
        "index =0\n",
        "for i in range(len(revIndex)):\n",
        "  if(revIndex[i] > maxi):\n",
        "    maxi = revIndex[i]\n",
        "    index = i\n",
        "# print(revIndex[1])\n",
        "print(\"Total number of sentences are \" + str(len(reviewsentencearray)))\n",
        "print(\"Maximim number of sentences in a review is \" + str(maxi))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "304\n",
            "Total number of sentences are 2508\n",
            "Maximim number of sentences in a review is 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPrJNHncQq_8"
      },
      "source": [
        "if( not (len(reviewsentencearray) == len(polarityarray) ==len(aspectarray))):\n",
        "  print(\"gone wrong some where\")\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYssNy0n4nsS"
      },
      "source": [
        "Till now we have extracted Info from XML, From now on let us create a dataframe out of them right now"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9x3FzPaA1lY"
      },
      "source": [
        "### introducing pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WC-IDGHpu-uO",
        "outputId": "a0661b61-0176-4f5a-c82b-6ff4a1357451"
      },
      "source": [
        "\n",
        "#Import pandas library\n",
        "import pandas as pd\n",
        "\n",
        "  \n",
        "result=[]\n",
        "for j in range(len(reviewsentencearray)):\n",
        "\n",
        "    result.append(polarityarray[j])\n",
        "    \n",
        "        \n",
        "data =[]\n",
        "# initialize list of lists\n",
        "for i in range(len(reviewsentencearray)):\n",
        "  data.append([ridarray[i], aspectarray[i],reviewsentencearray[i],result[i]])\n",
        "  \n",
        "# Create the pandas DataFrame\n",
        "DATA = pd.DataFrame(data, columns = ['rid','aspect','text','polarity'])\n",
        "\n",
        "DATA[100:150]\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rid</th>\n",
              "      <th>aspect</th>\n",
              "      <th>text</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>14</td>\n",
              "      <td>AMBIENCE#GENERAL</td>\n",
              "      <td>The ambience is pretty and nice for conversati...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>14</td>\n",
              "      <td>RESTAURANT#MISCELLANEOUS</td>\n",
              "      <td>The ambience is pretty and nice for conversati...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>15</td>\n",
              "      <td>LOCATION#GENERAL</td>\n",
              "      <td>If you've ever been along the river in Weehawk...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>15</td>\n",
              "      <td>SERVICE#GENERAL</td>\n",
              "      <td>Add to that great service and great food at a ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>15</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>Add to that great service and great food at a ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>15</td>\n",
              "      <td>FOOD#PRICES</td>\n",
              "      <td>Add to that great service and great food at a ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>15</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>The lava cake dessert was incredible and I rec...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>16</td>\n",
              "      <td>AMBIENCE#GENERAL</td>\n",
              "      <td>Once you step into Cosette, you're miraculousl...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>16</td>\n",
              "      <td>AMBIENCE#GENERAL</td>\n",
              "      <td>This tiny restaurant is as cozy as it gets, wi...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>16</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>The food was average to above-average; the Fre...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>16</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>The food was average to above-average; the Fre...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>16</td>\n",
              "      <td>FOOD#STYLE_OPTIONS</td>\n",
              "      <td>The food was average to above-average; the Fre...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>16</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>The food was average to above-average; the Fre...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>16</td>\n",
              "      <td>AMBIENCE#GENERAL</td>\n",
              "      <td>However, go for the ambience, and consider the...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>16</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>However, go for the ambience, and consider the...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>17</td>\n",
              "      <td>RESTAURANT#GENERAL</td>\n",
              "      <td>IT WAS HORRIBLE.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>17</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>The pizza was delivered cold and the cheese wa...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>17</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>The pizza was delivered cold and the cheese wa...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>17</td>\n",
              "      <td>FOOD#STYLE_OPTIONS</td>\n",
              "      <td>It looked like shredded cheese partly done - s...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>18</td>\n",
              "      <td>RESTAURANT#GENERAL</td>\n",
              "      <td>This has got to be one of the most overrated r...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>18</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>The pizza is overpriced and soggy.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>18</td>\n",
              "      <td>FOOD#PRICES</td>\n",
              "      <td>The pizza is overpriced and soggy.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>18</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>Yes, they use fancy ingredients, but even fanc...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>18</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>Yes, they use fancy ingredients, but even fanc...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>18</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>Yes, they use fancy ingredients, but even fanc...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>18</td>\n",
              "      <td>RESTAURANT#GENERAL</td>\n",
              "      <td>A big disappointment, all around.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>19</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>I think I've had some the best meals of my lif...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>19</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>The seafood is amazing, there's a good wine li...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>19</td>\n",
              "      <td>DRINKS#STYLE_OPTIONS</td>\n",
              "      <td>The seafood is amazing, there's a good wine li...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>19</td>\n",
              "      <td>FOOD#STYLE_OPTIONS</td>\n",
              "      <td>The seafood is amazing, there's a good wine li...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>19</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>The combination of super-fresh ingredients in ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>19</td>\n",
              "      <td>RESTAURANT#GENERAL</td>\n",
              "      <td>Worth the trip from Manhattan.</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>20</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>Best Pastrami I ever had and great portion wit...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>20</td>\n",
              "      <td>FOOD#STYLE_OPTIONS</td>\n",
              "      <td>Best Pastrami I ever had and great portion wit...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>20</td>\n",
              "      <td>FOOD#STYLE_OPTIONS</td>\n",
              "      <td>My wife had the fried shrimp which are huge an...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>20</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>My wife had the fried shrimp which are huge an...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>21</td>\n",
              "      <td>RESTAURANT#GENERAL</td>\n",
              "      <td>As a Japanese native, I've lived in the Trista...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>21</td>\n",
              "      <td>RESTAURANT#MISCELLANEOUS</td>\n",
              "      <td>This place is the most Japanese it can ever get.</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>21</td>\n",
              "      <td>RESTAURANT#MISCELLANEOUS</td>\n",
              "      <td>The signs, the specials menus, food, and even ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>21</td>\n",
              "      <td>FOOD#STYLE_OPTIONS</td>\n",
              "      <td>The signs, the specials menus, food, and even ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>21</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>The signs, the specials menus, food, and even ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>21</td>\n",
              "      <td>SERVICE#GENERAL</td>\n",
              "      <td>The signs, the specials menus, food, and even ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>21</td>\n",
              "      <td>RESTAURANT#GENERAL</td>\n",
              "      <td>This place is worth an one-hour drive.</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>21</td>\n",
              "      <td>RESTAURANT#GENERAL</td>\n",
              "      <td>I am so coming back here again, as much as I can.</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>22</td>\n",
              "      <td>RESTAURANT#GENERAL</td>\n",
              "      <td>Leon is an East Village gem: casual but hip, w...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>22</td>\n",
              "      <td>AMBIENCE#GENERAL</td>\n",
              "      <td>Leon is an East Village gem: casual but hip, w...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>22</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>Leon is an East Village gem: casual but hip, w...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>22</td>\n",
              "      <td>AMBIENCE#GENERAL</td>\n",
              "      <td>Leon is an East Village gem: casual but hip, w...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>22</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>Leon is an East Village gem: casual but hip, w...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>22</td>\n",
              "      <td>SERVICE#GENERAL</td>\n",
              "      <td>My wife and I always enjoy the young, not alwa...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     rid  ... polarity\n",
              "100   14  ...      1.0\n",
              "101   14  ...      1.0\n",
              "102   15  ...      1.0\n",
              "103   15  ...      1.0\n",
              "104   15  ...      1.0\n",
              "105   15  ...      1.0\n",
              "106   15  ...      1.0\n",
              "107   16  ...      1.0\n",
              "108   16  ...      1.0\n",
              "109   16  ...      1.0\n",
              "110   16  ...      0.0\n",
              "111   16  ...      1.0\n",
              "112   16  ...      0.0\n",
              "113   16  ...      1.0\n",
              "114   16  ...      0.5\n",
              "115   17  ...      0.0\n",
              "116   17  ...      0.0\n",
              "117   17  ...      0.0\n",
              "118   17  ...      0.0\n",
              "119   18  ...      0.0\n",
              "120   18  ...      0.0\n",
              "121   18  ...      0.0\n",
              "122   18  ...      1.0\n",
              "123   18  ...      0.0\n",
              "124   18  ...      0.0\n",
              "125   18  ...      0.0\n",
              "126   19  ...      1.0\n",
              "127   19  ...      1.0\n",
              "128   19  ...      1.0\n",
              "129   19  ...      1.0\n",
              "130   19  ...      1.0\n",
              "131   19  ...      1.0\n",
              "132   20  ...      1.0\n",
              "133   20  ...      1.0\n",
              "134   20  ...      1.0\n",
              "135   20  ...      1.0\n",
              "136   21  ...      1.0\n",
              "137   21  ...      1.0\n",
              "138   21  ...      1.0\n",
              "139   21  ...      1.0\n",
              "140   21  ...      1.0\n",
              "141   21  ...      1.0\n",
              "142   21  ...      1.0\n",
              "143   21  ...      1.0\n",
              "144   22  ...      1.0\n",
              "145   22  ...      1.0\n",
              "146   22  ...      1.0\n",
              "147   22  ...      1.0\n",
              "148   22  ...      1.0\n",
              "149   22  ...      1.0\n",
              "\n",
              "[50 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuFeuFxV55VT"
      },
      "source": [
        "**Done, Now let us clean the text using standard methods avaliable for US:XD**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnu-9qgN6nK3"
      },
      "source": [
        "### Cleaning Step:  Removing Links, HTML, Emoji, Punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgRblift5xUs"
      },
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "\n",
        "def remove_URL(text):\n",
        "    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
        "    return url.sub(r\"\", text)\n",
        "\n",
        "\n",
        "def remove_html(text):\n",
        "    html = re.compile(r\"<.*?>\")\n",
        "    return html.sub(r\"\", text)\n",
        "\n",
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\n",
        "        \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        \"]+\",\n",
        "        flags=re.UNICODE,\n",
        "    )\n",
        "    return emoji_pattern.sub(r\"\", string)\n",
        "\n",
        "def remove_punct(text):\n",
        "  table = str.maketrans(\"\", \"\", string.punctuation)\n",
        "  return text.translate(table)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhq54iW08a5C"
      },
      "source": [
        "We have to remove stop words in the sentences for making it more efficient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdVdUxcr8VSE",
        "outputId": "ad946b45-c59c-4033-e5b5-b720c8b0f566"
      },
      "source": [
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "stop = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in stop]\n",
        "\n",
        "    return \" \".join(text)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "tzyWB7DM7gb-",
        "outputId": "0e49da30-a487-427d-acc4-4dbbf177224b"
      },
      "source": [
        "# calling all the functions declared above\n",
        "\n",
        "DATA.text = DATA.text.map(lambda x: remove_URL(x))\n",
        "DATA.text = DATA.text.map(lambda x: remove_html(x))\n",
        "DATA.text = DATA.text.map(lambda x: remove_emoji(x))\n",
        "DATA.text = DATA.text.map(lambda x: remove_punct(x))\n",
        "DATA.text = DATA.text.map(remove_stopwords)\n",
        "DATA"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rid</th>\n",
              "      <th>aspect</th>\n",
              "      <th>text</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>RESTAURANT#GENERAL</td>\n",
              "      <td>judging previous posts used good place longer</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>SERVICE#GENERAL</td>\n",
              "      <td>four us arrived noon place empty staff acted l...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>SERVICE#GENERAL</td>\n",
              "      <td>never brought us complimentary noodles ignored...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>food lousy sweet salty portions tiny</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>FOOD#STYLE_OPTIONS</td>\n",
              "      <td>food lousy sweet salty portions tiny</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2503</th>\n",
              "      <td>349</td>\n",
              "      <td>SERVICE#GENERAL</td>\n",
              "      <td>waitress came check us every minutes began cle...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2504</th>\n",
              "      <td>349</td>\n",
              "      <td>SERVICE#GENERAL</td>\n",
              "      <td>couldnt ignore fact reach plate one friends mi...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2505</th>\n",
              "      <td>349</td>\n",
              "      <td>SERVICE#GENERAL</td>\n",
              "      <td>put check without asking done came check bill ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2506</th>\n",
              "      <td>349</td>\n",
              "      <td>RESTAURANT#GENERAL</td>\n",
              "      <td>wish could like place wish someone would retra...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2507</th>\n",
              "      <td>349</td>\n",
              "      <td>SERVICE#GENERAL</td>\n",
              "      <td>wish could like place wish someone would retra...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2508 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      rid  ... polarity\n",
              "0       0  ...      0.0\n",
              "1       0  ...      0.0\n",
              "2       0  ...      0.0\n",
              "3       0  ...      0.0\n",
              "4       0  ...      0.0\n",
              "...   ...  ...      ...\n",
              "2503  349  ...      0.0\n",
              "2504  349  ...      0.0\n",
              "2505  349  ...      0.0\n",
              "2506  349  ...      0.0\n",
              "2507  349  ...      0.0\n",
              "\n",
              "[2508 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhzmIEsF90XX"
      },
      "source": [
        "**Recap of What we have done till now:**\n",
        "\n",
        "\n",
        "1. Extracted all the relevant information from the xml file\n",
        "2. Created a pandas dataframe out of the required data for making our lives simpler\n",
        "3. Cleaned the data from pincuations, links, emojis, html   *italicized text*\n",
        "\n",
        "**Now let us create word embeddings for proceeding with the implementaion**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqPJkzZ4Ag2y"
      },
      "source": [
        "### Tokenizing, Padding, Preparing Deliverables for embedding Matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeudQlxaAl3M",
        "outputId": "da94e0dc-a8e0-48dc-ec4a-34823de22a87"
      },
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install keras\n",
        "!{sys.executable} -m pip install tensorflow\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def create_corpus_tk(df):\n",
        "    corpus = []\n",
        "    for text in df[\"text\"]:\n",
        "        words = [word.lower() for word in word_tokenize(text)]\n",
        "        corpus.append(words)\n",
        "    return corpus\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.22.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.42.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW7AwOMFD8qu",
        "outputId": "ef25f675-e9f6-4384-ca35-3d65bde44960"
      },
      "source": [
        "corpus = create_corpus_tk(DATA)\n",
        "\n",
        "print(\"corpus[i] looks like:\")\n",
        "print(corpus[0])\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "maxi = -1\n",
        "for i in range(len(reviewsentencearray)):\n",
        "  if (len(corpus[i]) > maxi):\n",
        "    maxi = len(corpus[i])\n",
        "\n",
        "print(\"maximum words in a sentence are \" + str(maxi))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus[i] looks like:\n",
            "['judging', 'previous', 'posts', 'used', 'good', 'place', 'longer']\n",
            "---------------------------------\n",
            "maximum words in a sentence are 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cukXSbGiFJFt",
        "outputId": "c21a7cb6-0082-49a5-ca8c-0815b5f5a325"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=1000000)\n",
        "tokenizer.fit_on_texts(DATA.text)\n",
        "word_index = tokenizer.word_index\n",
        "print(\"number of unique words just for fun:\", len(word_index))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of unique words just for fun: 3052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_Ap2-h1F8e_"
      },
      "source": [
        "Now let us create train sequences which can be processed with embeddings for catching the relation better\n",
        "\n",
        "**IMPORTANT OBSERVATIONS:<br>\n",
        "1) MAXIMUM NUMBER OF WORDS IN A SENTENCE IS : 35 <br>\n",
        "2) MAXIMUM NUMBER OF SENTENCES IN A REVIEW IS : 44<br>\n",
        "3) TOTAL NUMBER OF REVIEWS : 350**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnE45cgYF6lp",
        "outputId": "9f21262b-e244-4ca7-e436-415d3c7c882c"
      },
      "source": [
        "import numpy as np\n",
        "sentences = DATA.text\n",
        "sequences = tokenizer.texts_to_sequences(DATA.text)\n",
        "paddedsequences = pad_sequences(\n",
        "sequences, maxlen=35, truncating=\"post\", padding=\"post\"\n",
        ")\n",
        "print(len(paddedsequences))\n",
        "pp=np.array(DATA.polarity)\n",
        "print(len(DATA.polarity))\n",
        "print(type(paddedsequences[0]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2508\n",
            "2508\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYDZVQeR_y2u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "c3723a64-4c18-48b5-c2fc-bf56a1c96ed8"
      },
      "source": [
        "newpaddingsequences = []\n",
        "newpolarity = []\n",
        "newaspect= []\n",
        "newrid=[]\n",
        "temp=[]\n",
        "import numpy as np\n",
        "padding = np.zeros((35))\n",
        "\n",
        "j=0\n",
        "for i in range(349):\n",
        "\n",
        "  limit44 = 0\n",
        "  while(ridarray[j]==i):\n",
        "    newpaddingsequences.append(paddedsequences[j])\n",
        "    newpolarity.append(polarityarray[j])\n",
        "    newaspect.append(aspectarray[j])\n",
        "    newrid.append(i)\n",
        "\n",
        "    limit44+=1\n",
        "    j+=1\n",
        "    #print(j)\n",
        "    #print(i)\n",
        "  while(limit44 < 44):\n",
        "    newpaddingsequences.append(padding)\n",
        "    newpolarity.append(0.5)\n",
        "    newaspect.append(\"FOOD#QUALITY\")\n",
        "    newrid.append(i)\n",
        "    limit44 +=1\n",
        "\n",
        "# print(len(newpaddingsequences))\n",
        "# print(len(newpolarity[:44]))\n",
        "newpaddingsequences = np.array(newpaddingsequences)\n",
        "newpolarity = np.array(newpolarity)\n",
        "newaspect = np.array(newaspect)\n",
        "newrid = np.array(newrid)\n",
        "temp = np.array(temp)\n",
        "new_aspect_array=[]\n",
        "for i in range(len(aspectarray)):\n",
        "    new_aspect_array.append(((aspectarray[i]).split('#')))\n",
        "    new_aspect_array[i][0]=new_aspect_array[i][0].lower()\n",
        "    new_aspect_array[i][1]=new_aspect_array[i][1].lower()\n",
        "    if(new_aspect_array[i][1]=='style_options'):\n",
        "        new_aspect_array[i][1]='style'\n",
        "#         print(\"yes\")\n",
        "\n",
        "# print((new_aspect_array))\n",
        "data = []\n",
        "for i in range(len(newpaddingsequences)):\n",
        "  data.append([newrid[i], newaspect[i],newpaddingsequences[i],newpolarity[i]])\n",
        "  \n",
        "# Create the pandas DataFrame\n",
        "DATA = pd.DataFrame(data, columns = ['rid','aspect','sequence','polarity'])\n",
        "\n",
        "\n",
        "DATA\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rid</th>\n",
              "      <th>aspect</th>\n",
              "      <th>sequence</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>RESTAURANT#GENERAL</td>\n",
              "      <td>[2058.0, 609.0, 2059.0, 843.0, 4.0, 5.0, 610.0...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>SERVICE#GENERAL</td>\n",
              "      <td>[202.0, 34.0, 516.0, 2060.0, 5.0, 411.0, 11.0,...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>SERVICE#GENERAL</td>\n",
              "      <td>[17.0, 611.0, 34.0, 612.0, 517.0, 1417.0, 2063...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>[1.0, 845.0, 258.0, 613.0, 162.0, 343.0, 0.0, ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>FOOD#STYLE_OPTIONS</td>\n",
              "      <td>[1.0, 845.0, 258.0, 613.0, 162.0, 343.0, 0.0, ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15351</th>\n",
              "      <td>348</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15352</th>\n",
              "      <td>348</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15353</th>\n",
              "      <td>348</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15354</th>\n",
              "      <td>348</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15355</th>\n",
              "      <td>348</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15356 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       rid  ... polarity\n",
              "0        0  ...      0.0\n",
              "1        0  ...      0.0\n",
              "2        0  ...      0.0\n",
              "3        0  ...      0.0\n",
              "4        0  ...      0.0\n",
              "...    ...  ...      ...\n",
              "15351  348  ...      0.5\n",
              "15352  348  ...      0.5\n",
              "15353  348  ...      0.5\n",
              "15354  348  ...      0.5\n",
              "15355  348  ...      0.5\n",
              "\n",
              "[15356 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJe2pFSxKyyc"
      },
      "source": [
        "This sequencing and stuff is done, now let us go to word embedddings baby"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aClaj7ZFbaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0058fee9-fa2d-4468-b7cb-1b7a2bb1cab2"
      },
      "source": [
        "\n",
        "train_size=2009\n",
        "\n",
        "final_train_sequences = paddedsequences[:train_size]\n",
        "# print(type(final_train_sequences[4356][0]))\n",
        "# final_train_aspect = newaspect[:train_size]\n",
        "final_train_labels = pp[:train_size]\n",
        "# for i in range(len(final_train_labels)):\n",
        "#     if(final_train_labels[i]=='negative'):\n",
        "#         print(i)\n",
        "\n",
        "final_test_sequences = paddedsequences[train_size:]\n",
        "# final_test_aspect = newaspect[train_size:]\n",
        "final_test_labels = pp[train_size:]\n",
        "\n",
        "print(final_test_sequences)\n",
        "\n",
        "# train_size=300\n",
        "\n",
        "# final_train_sequences = newpaddingsequences[:train_size*44]\n",
        "# # print(type(final_train_sequences[4356][0]))\n",
        "# final_train_aspect = newaspect[:train_size*44]\n",
        "# final_train_labels = newpolarity[:train_size*44]\n",
        "# # for i in range(len(final_train_labels)):\n",
        "# #     if(final_train_labels[i]=='negative'):\n",
        "# #         print(i)\n",
        "\n",
        "# final_test_sequences = newpaddingsequences[train_size*44:]\n",
        "# final_test_aspect = newaspect[train_size*44:]\n",
        "# final_test_labels = newpolarity[train_size*44:]\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  37    1    0 ...    0    0    0]\n",
            " [2821  647    0 ...    0    0    0]\n",
            " [   2    1    0 ...    0    0    0]\n",
            " ...\n",
            " [ 605  347  292 ...    0    0    0]\n",
            " [ 249   91    7 ...    0    0    0]\n",
            " [ 249   91    7 ...    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs00kiywK8Jl"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsZJKx8QLCdr"
      },
      "source": [
        "import numpy as np\n",
        "embedding_dict = {}\n",
        "with open(\"glove.twitter.27B.100d.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vectors = np.asarray(values[1:], \"float32\")\n",
        "        embedding_dict[word] = vectors\n",
        "f.close()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JACYxi0bXeB"
      },
      "source": [
        "embedding_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dUogiujbXeB"
      },
      "source": [
        "num_words = len(word_index) +1\n",
        "embedding_matrix = np.zeros((num_words, 100))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i < num_words:\n",
        "        emb_vec = embedding_dict.get(word)\n",
        "        if emb_vec is not None:\n",
        "            embedding_matrix[i] = emb_vec"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIn3WE1-bXeB",
        "outputId": "498586be-1b34-45af-ac20-0744383f62f1"
      },
      "source": [
        "print((embedding_matrix.shape))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3053, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvJ2pqfnbXeC"
      },
      "source": [
        "aa=new_aspect_array[0][0]\n",
        "\n",
        "embedding_dict.get(aa)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzYSkdJFbXeC",
        "outputId": "76ad6840-7d43-431d-9e30-e83b42337aa1"
      },
      "source": [
        "print(final_train_sequences.shape)\n",
        "# print(train_sentences.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2009, 35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv6qVwq9bXeC"
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, Input\n",
        "from keras.initializers import Constant\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(\n",
        "        num_words,\n",
        "        100,\n",
        "        embeddings_initializer=Constant(embedding_matrix),\n",
        "        input_length=35,\n",
        "        trainable=False,\n",
        "    )\n",
        ")\n",
        "model.add(Bidirectional(LSTM(15,dropout=0.5)))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=3e-4)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "model.summary"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP0DuBJ1bXeC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2b4d304-53eb-463b-f7f0-30f79771abbc"
      },
      "source": [
        "print(final_train_sequences.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2009, 35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYysj5E2bXeD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18daa789-64e9-4e0f-827d-482c69e92c84"
      },
      "source": [
        "history = model.fit(\n",
        "    final_train_sequences,\n",
        "    final_train_labels,\n",
        "    epochs=20,\n",
        "    validation_data=(final_train_sequences,final_train_labels),\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 6s 44ms/step - loss: 0.6585 - accuracy: 0.6257 - val_loss: 0.5987 - val_accuracy: 0.7203\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 0.5797 - accuracy: 0.7188 - val_loss: 0.5570 - val_accuracy: 0.7203\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.5416 - accuracy: 0.7203 - val_loss: 0.4985 - val_accuracy: 0.7203\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.4911 - accuracy: 0.7317 - val_loss: 0.4503 - val_accuracy: 0.7357\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.4706 - accuracy: 0.7471 - val_loss: 0.4338 - val_accuracy: 0.7621\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.4582 - accuracy: 0.7646 - val_loss: 0.4207 - val_accuracy: 0.7894\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.4389 - accuracy: 0.7785 - val_loss: 0.4101 - val_accuracy: 0.7999\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 0.4502 - accuracy: 0.7790 - val_loss: 0.4053 - val_accuracy: 0.8009\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 0.4362 - accuracy: 0.7790 - val_loss: 0.4004 - val_accuracy: 0.8059\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 0.4356 - accuracy: 0.7830 - val_loss: 0.3922 - val_accuracy: 0.7999\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.4355 - accuracy: 0.7865 - val_loss: 0.3891 - val_accuracy: 0.8104\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 0.4180 - accuracy: 0.7989 - val_loss: 0.3868 - val_accuracy: 0.8059\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.4116 - accuracy: 0.7944 - val_loss: 0.3834 - val_accuracy: 0.8153\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.4156 - accuracy: 0.7899 - val_loss: 0.3752 - val_accuracy: 0.8183\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.4138 - accuracy: 0.7885 - val_loss: 0.3720 - val_accuracy: 0.8203\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.4004 - accuracy: 0.7994 - val_loss: 0.3699 - val_accuracy: 0.8198\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.4039 - accuracy: 0.7959 - val_loss: 0.3655 - val_accuracy: 0.8118\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.3964 - accuracy: 0.7959 - val_loss: 0.3616 - val_accuracy: 0.8173\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.3994 - accuracy: 0.7999 - val_loss: 0.3597 - val_accuracy: 0.8263\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.4005 - accuracy: 0.7964 - val_loss: 0.3570 - val_accuracy: 0.8243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCn84yUIbXeD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc0d9f0-804e-41c1-b70b-5b42bd05120e"
      },
      "source": [
        "print(final_test_sequences.shape,final_test_labels.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(499, 35) (499,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkSN5eyubXeD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2d1290e-29ef-4b0d-ae89-34682b30f375"
      },
      "source": [
        "pred = model.predict(final_test_sequences)\n",
        "print(pred.shape)\n",
        "print(pred[0])\n",
        "pred_int=[]\n",
        "\n",
        "pred_int = pred.round().astype(\"int\")\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(499, 1)\n",
            "[0.9700526]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKA1Wq6xbXeD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df0d1b7-3a8f-4d4e-9902-e381b9ccfa1c"
      },
      "source": [
        "# print(final_test_sequences)\n",
        "print(len(final_test_labels))\n",
        "ccc=0\n",
        "for i in range(len(final_test_labels)):\n",
        "    if(pred_int[i]==final_test_labels[i]):\n",
        "#         print(pred_int[i])\n",
        "        ccc+=1\n",
        "print(ccc)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "499\n",
            "366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjpDuJ28svan",
        "outputId": "72e866e6-7c80-4cbb-c919-fe6456a5dc75"
      },
      "source": [
        "rev_polarity=[]\n",
        "j=0\n",
        "for j in range(len(revIndex)):\n",
        "    sum_1=0\n",
        "    count_review=0\n",
        "    average=0\n",
        "    for i in range(len(ridarray)):\n",
        "        if(ridarray[i]==j):\n",
        "            count_review+=1\n",
        "            sum_1+=pp[i]\n",
        "    average=sum_1/count_review\n",
        "    average=average.round().astype(\"int\")\n",
        "    rev_polarity.append(average)\n",
        "\n",
        "print(rev_polarity)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az0PSNGTsvan"
      },
      "source": [
        "found_polarity=[]\n",
        "# print(type(pred_int[0]))\n",
        "j=0\n",
        "# print(len(pred))\n",
        "for j in range(len(revIndex)):\n",
        "    sum_1=0\n",
        "    count_review=0\n",
        "    average=0\n",
        "    for i in range(len(pred)):\n",
        "\n",
        "        if(ridarray[train_size+i]==j):\n",
        "            count_review+=1\n",
        "            sum_1+=pred_int[i]\n",
        "    if(count_review==0):\n",
        "        continue\n",
        "    average=sum_1/count_review\n",
        "    average=average.round().astype(\"int\")\n",
        "    found_polarity.append(average)\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chumC6uAsvan",
        "outputId": "9935b1ad-73db-4966-c700-7977b7bb35c2"
      },
      "source": [
        "count=0\n",
        "aa=(ridarray[train_size])\n",
        "print(len(found_polarity))\n",
        "for i in range(len(found_polarity)):\n",
        "    if(found_polarity[i][0]==rev_polarity[aa+i]):\n",
        "        count+=1\n",
        "print(count)\n",
        "print(count/len(found_polarity)*100,\"%\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44\n",
            "37\n",
            "84.0909090909091 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dluqa6mbsvan",
        "outputId": "8b79b42d-9e3d-4796-cf24-e6dd56b0a3a2"
      },
      "source": [
        "entity_matrix=[]\n",
        "attribute_matrix=[]\n",
        "aspect_embedding=[]\n",
        "\n",
        "for i in range(len(new_aspect_array)):\n",
        "    entity=new_aspect_array[i][0]\n",
        "    entity_matrix=embedding_dict.get(entity)\n",
        "\n",
        "    attribute=new_aspect_array[i][1]\n",
        "    attribute_matrix=embedding_dict.get(attribute)\n",
        "\n",
        "    aspect_embedding.append((attribute_matrix+entity_matrix)/2)\n",
        "\n",
        "aspect_embedding = np.array(aspect_embedding)\n",
        "print(aspect_embedding.shape)\n",
        "print(len(aspect_embedding))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2508, 100)\n",
            "2508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9brAkzFqEj7B",
        "outputId": "ec4e297f-f634-4adb-afb6-b59c9cbdcc82"
      },
      "source": [
        "akidea  = model.predict(final_train_sequences)\n",
        "print(akidea.shape)\n",
        "print(akidea[0])\n",
        "akidea_int=[]\n",
        "\n",
        "akidea_int = akidea.round().astype(\"int\")\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2009, 1)\n",
            "[0.24216396]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFTJgN9XEGRd"
      },
      "source": [
        "step_train_sequences=[]\n",
        "step_train_labels=[]\n",
        "for i in range (len(akidea)):\n",
        "  temp=[]\n",
        "  for j in range (len(aspect_embedding[i])):\n",
        "\n",
        "    temp.append(float(aspect_embedding[i][j]))\n",
        "    \n",
        "    \n",
        "  \n",
        "  temp.append(akidea[i])\n",
        "  step_train_sequences.append(temp)\n",
        "  step_train_labels.append(polarityarray[i])\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "for i in range(len(step_train_labels)):\n",
        "  if(step_train_labels[i]==0.5):\n",
        "    zendaya= random.randint(0,9)\n",
        "    if(zendaya < 5):\n",
        "      step_train_labels[i] = 0.0\n",
        "    else:\n",
        "      step_train_labels[i] = 1.0\n",
        "\n",
        "step_train_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceTSLmwrJVos"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, Input\n",
        "from keras.initializers import Constant\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "rev_model = Sequential()\n",
        "model.add(\n",
        "    Embedding(\n",
        "        num_words,\n",
        "        100,\n",
        "        embeddings_initializer=Constant(embedding_matrix),\n",
        "        input_length=101,\n",
        "        trainable=False,\n",
        "    )\n",
        ")\n",
        "\n",
        "#rev_model.add(Embedding(1000000, 15, input_length=101))\n",
        "rev_model.add(Bidirectional(LSTM(15,dropout=0.5)))\n",
        "rev_model.add(Dense(1, activation=\"sigmoid\"))\n",
        "rev_model.add(Dense(1, activation=\"softmax\"))\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=3e-4)\n",
        "\n",
        "rev_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "JgnQ6GX_Kv-5",
        "outputId": "a76feb03-3b22-45b8-c5ec-ee5f5e2d3b07"
      },
      "source": [
        "# step_train_sequences=np.asarray(step_train_sequences).astype(np.float32)\n",
        "# step_train_labels=np.asarray(step_train_labels).astype(np.float32)\n",
        "\n",
        "\n",
        "history1 = rev_model.fit(\n",
        "    step_train_sequences,\n",
        "    step_train_labels,\n",
        "    epochs=20,\n",
        "    validation_data=(step_train_sequences,step_train_labels),\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-7fd41dd5b0d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_train_sequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep_train_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 213, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_12\" (type Sequential).\n    \n    Input 0 of layer \"bidirectional_12\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 101)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 101), dtype=float32)\n      • training=True\n      • mask=None\n"
          ]
        }
      ]
    }
  ]
}